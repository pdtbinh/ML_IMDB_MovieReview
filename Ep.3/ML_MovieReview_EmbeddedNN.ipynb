{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project Serie 1:\n",
    "# IMDB Movie Review Sentiment Classification \n",
    "# Episode 3: Embedding Word Matrix\n",
    "This episode focuses on fitting and testing the data with embedding word matrix usually used in NLP and a densely connected network.\n",
    "\n",
    "## I. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply, Embedding, Reshape, Flatten, Dropout, GRU\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda, Softmax, Conv1D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/tieubinh03/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Users/tieubinh03/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = tf.keras.datasets.imdb.get_word_index(path=\"imdb_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words count: 88584\n"
     ]
    }
   ],
   "source": [
    "vocab_len = len(word_dict)\n",
    "print(\"Total words count:\", vocab_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_cmt_len = 2000\n",
    "max_index = 25000\n",
    "\n",
    "def padding(initial_x):\n",
    "    output = np.zeros((chosen_cmt_len))\n",
    "    for i in range(chosen_cmt_len):\n",
    "        if i < len(initial_x) and initial_x[i] < max_index:\n",
    "            output[i] = initial_x[i]\n",
    "        else:\n",
    "            output[i] = 0\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_padded = np.zeros((len(x_train), chosen_cmt_len))\n",
    "for i in range(len(x_train)):\n",
    "    x_train_padded[i] = padding(x_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_padded = np.zeros((len(x_test), chosen_cmt_len))\n",
    "for i in range(len(x_test)):\n",
    "    x_test_padded[i] = padding(x_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Machine Learning Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_s = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model:\n",
    "def model():\n",
    "    \n",
    "    # Retrieving inputs\n",
    "    X_input = Input(shape=(chosen_cmt_len,))\n",
    "    \n",
    "    # Embedding meanings\n",
    "    embedding = Embedding(max_index, e_s)(X_input)\n",
    "    \n",
    "    drop = Dropout(0.9)(embedding)\n",
    "    \n",
    "    flatten = Flatten()(drop)\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid',\n",
    "                   kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                   bias_regularizer=regularizers.l2(1e-4),\n",
    "                   activity_regularizer=regularizers.l2(1e-5)\n",
    "                  )(flatten)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 2000)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 2000, 20)          500000    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2000, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 40000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 40001     \n",
      "=================================================================\n",
      "Total params: 540,001\n",
      "Trainable params: 540,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer for the model\n",
    "learning_rate = 5e-3\n",
    "opt = Adam(lr=learning_rate, decay=1e-5)\n",
    "model.compile(optimizer=opt, \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", threshold=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Fitting data:\n",
      "25/25 [==============================] - 11s 415ms/step - loss: 0.7443 - binary_accuracy: 0.4992\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.6885 - binary_accuracy: 0.5351\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 411ms/step - loss: 0.6308 - binary_accuracy: 0.6651\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.5485 - binary_accuracy: 0.7708\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 399ms/step - loss: 0.4599 - binary_accuracy: 0.8007\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3946 - binary_accuracy: 0.8506\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 399ms/step - loss: 0.3594 - binary_accuracy: 0.8498\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3469 - binary_accuracy: 0.8667\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 396ms/step - loss: 0.3081 - binary_accuracy: 0.8791\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3262 - binary_accuracy: 0.8763\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 397ms/step - loss: 0.2744 - binary_accuracy: 0.8964\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3131 - binary_accuracy: 0.8804\n",
      "\n",
      "\n",
      "Epoch: 7\n",
      "Fitting data:\n",
      "25/25 [==============================] - 12s 455ms/step - loss: 0.2632 - binary_accuracy: 0.9004\n",
      "Testing data:\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.3134 - binary_accuracy: 0.8803\n",
      "\n",
      "\n",
      "Epoch: 8\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 375ms/step - loss: 0.2395 - binary_accuracy: 0.9108\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3093 - binary_accuracy: 0.8813\n",
      "\n",
      "\n",
      "Epoch: 9\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 397ms/step - loss: 0.2342 - binary_accuracy: 0.9138\n",
      "Testing data:\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.3081 - binary_accuracy: 0.8816\n",
      "\n",
      "\n",
      "Epoch: 10\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 403ms/step - loss: 0.2359 - binary_accuracy: 0.9142\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3074 - binary_accuracy: 0.8814\n",
      "\n",
      "\n",
      "Epoch: 11\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 384ms/step - loss: 0.2246 - binary_accuracy: 0.9165\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 1ms/step - loss: 0.3066 - binary_accuracy: 0.8816\n",
      "\n",
      "\n",
      "Epoch: 12\n",
      "Fitting data:\n",
      "25/25 [==============================] - 9s 372ms/step - loss: 0.2343 - binary_accuracy: 0.9136\n",
      "Testing data:\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.3075 - binary_accuracy: 0.8819\n",
      "\n",
      "\n",
      "Epoch: 13\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 380ms/step - loss: 0.2333 - binary_accuracy: 0.9138\n",
      "Testing data:\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.3071 - binary_accuracy: 0.8817\n",
      "\n",
      "\n",
      "Epoch: 14\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 370ms/step - loss: 0.2318 - binary_accuracy: 0.9143\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3072 - binary_accuracy: 0.8815\n",
      "\n",
      "\n",
      "Epoch: 15\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 404ms/step - loss: 0.2298 - binary_accuracy: 0.9154\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3072 - binary_accuracy: 0.8816\n",
      "\n",
      "\n",
      "Epoch: 16\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 397ms/step - loss: 0.2327 - binary_accuracy: 0.9142\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3071 - binary_accuracy: 0.8816\n",
      "\n",
      "\n",
      "Epoch: 17\n",
      "Fitting data:\n",
      "25/25 [==============================] - 9s 379ms/step - loss: 0.2278 - binary_accuracy: 0.9181\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3071 - binary_accuracy: 0.8818\n",
      "\n",
      "\n",
      "Epoch: 18\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 397ms/step - loss: 0.2300 - binary_accuracy: 0.9185\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3071 - binary_accuracy: 0.8817\n",
      "\n",
      "\n",
      "Epoch: 19\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 381ms/step - loss: 0.2399 - binary_accuracy: 0.9107\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3071 - binary_accuracy: 0.8817\n",
      "\n",
      "\n",
      "Epoch: 20\n",
      "Fitting data:\n",
      "25/25 [==============================] - 10s 403ms/step - loss: 0.2292 - binary_accuracy: 0.9139\n",
      "Testing data:\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3071 - binary_accuracy: 0.8817\n",
      "\n",
      "\n",
      "Optimal testing accuracy is: 88.19%\n"
     ]
    }
   ],
   "source": [
    "# Storing histories\n",
    "histories = []\n",
    "testings  = []\n",
    "\n",
    "# Track testing accuracy\n",
    "prev_acc = 0\n",
    "curr_acc = 0.01\n",
    "\n",
    "# Max testing accuracy\n",
    "max_acc = 0\n",
    "\n",
    "# Fitting and evaluating the model after epochs\n",
    "epoch = 1\n",
    "\n",
    "# Keep training as long as testing accuracy on testing set is still increasing\n",
    "while epoch < 21:\n",
    "    # Fitting\n",
    "    print(\"Epoch:\", epoch)\n",
    "    print(\"Fitting data:\")\n",
    "    history = model.fit(x = x_train_padded, y = np.array(y_train).reshape(25000, 1), epochs=1, batch_size=1000)\n",
    "    \n",
    "    # Evaluating\n",
    "    print(\"Testing data:\")\n",
    "    testing = model.evaluate(x_test_padded, np.array(y_test).reshape(25000, 1))\n",
    "    \n",
    "    # Assigning max accuracy\n",
    "    if testing[1] > max_acc:\n",
    "        max_acc = testing[1]\n",
    "        \n",
    "    # Assigning test accuracy\n",
    "    prev_acc = curr_acc\n",
    "    curr_acc = testing[1]\n",
    "        \n",
    "    # Adjust learning rate\n",
    "    if prev_acc > curr_acc:\n",
    "        learning_rate /= 10\n",
    "        opt = Adam(lr=learning_rate, decay=1e-5)\n",
    "        model.compile(optimizer=opt, \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", threshold=0.5)])\n",
    "    \n",
    "    # Storing\n",
    "    histories.append(history)\n",
    "    testings.append(testing)\n",
    "    \n",
    "    epoch += 1\n",
    "    print('\\n')\n",
    "\n",
    "print(\"Optimal testing accuracy is: {:.2f}%\".format(max_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1575 - binary_accuracy: 0.9611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15848954021930695, 0.9601200222969055]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train_padded, np.array(y_train).reshape(25000, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Summary:\n",
    "Embedding matrix performed quite well given the number of parameters trained was relatively small compared to the model used in previous episode.\n",
    "\n",
    "|-|Loss|Accuracy|Sample size|\n",
    "|-|-|-|-|\n",
    "|Training|0.16|96.1%|25,000|\n",
    "|Testing |0.31|88.2%|25,000|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Thank you:\n",
    "Thank you for viewing my project. See you in the next episode."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
